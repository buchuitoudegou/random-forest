{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from random import randrange\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999998\n",
      "9999998\n",
      "9999998\n",
      "9999998\n",
      "9999998\n"
     ]
    }
   ],
   "source": [
    "# read all data from train\n",
    "train_data = []\n",
    "train_label = []\n",
    "for i in range(1, 6):\n",
    "    tmp = pd.read_csv('./data/train%d.csv' % i)\n",
    "    label = pd.read_csv('./data/label%d.csv' % i)\n",
    "    train_data.append(tmp)\n",
    "    train_label.append(label)\n",
    "x = train_data[0]\n",
    "y = train_label[0]\n",
    "for i in range(4):\n",
    "    x = np.vstack((x, train_data[i]))\n",
    "    y = np.vstack((y, train_label[i]))\n",
    "dataset = np.hstack((x, y))\n",
    "kf = KFold(n_splits=5)\n",
    "k_fold_data = []\n",
    "for tra_idx, val_idx in kf.split(dataset):\n",
    "    tra = dataset[tra_idx]\n",
    "    val = dataset[val_idx]\n",
    "    k_fold_data.append((tra, val))\n",
    "    print(len(tra) + len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    \"\"\"\n",
    "    description: split the current dataset by the `index`th feature and value\n",
    "    \"\"\"\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def gini_index(groups, class_values):\n",
    "    \"\"\"\n",
    "    description: evaluate the gini value of the current groups, \n",
    "    containing the left group and the right group, splited by the nth feature.\n",
    "    `class_values` are all the possible values in the label column.\n",
    "    \"\"\"\n",
    "    gini = 0.0\n",
    "    for class_value in class_values:\n",
    "        for group in groups:\n",
    "            if len(group) == 0:\n",
    "                continue\n",
    "            proportion = [row[-1] for row in group].count(class_value) / len(group)\n",
    "            gini += (proportion * (1.0 - proportion))\n",
    "    return gini\n",
    "\n",
    "def to_terminal(group):\n",
    "    \"\"\"\n",
    "    description: terminate the split and set the most frequent value as the output\n",
    "    \"\"\"\n",
    "    output = [row[-1] for row in group]\n",
    "    return max(set(output), key=output.count)\n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "    \"\"\"\n",
    "    description: choose a feature, which gains the highest gini value,\n",
    "    to split the dataset.\n",
    "    \"\"\"\n",
    "    class_values = [row[-1] for row in dataset]\n",
    "    s_index, s_value, s_score, s_groups = 999999, 999999, 999999, None\n",
    "    cur_features = [] # choose partition feature randomly\n",
    "    while len(cur_features) < log(2, n_features):\n",
    "        index = randrange(len(dataset[0] - 1))\n",
    "        if index not in cur_features:\n",
    "            cur_features.append(index)\n",
    "    for index in cur_features:\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < s_score:\n",
    "                s_index, s_value, s_score, b_groups = index, row[index], gini, groups\n",
    "    return { 'index': s_index, 'value': s_value, 'groups': s_groups }\n",
    "\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    \"\"\"\n",
    "    description: split the node recursively.\n",
    "    \"\"\"\n",
    "    left, right = node['group']\n",
    "    del(node['group'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    \"\"\"\n",
    "    description: build a tree\n",
    "    \"\"\"\n",
    "    root = get_split(train, n_features)\n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "    \"\"\"\n",
    "    description: make prediction with the tree, navigating it and get the output\n",
    "    \"\"\"\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "def sub_sample(dataset, ratio):\n",
    "    \"\"\"\n",
    "    description: select the data ramdomly.\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    trees = []\n",
    "    for i in range(n_trees):\n",
    "        sample = sub_sample(train, sample_size)\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "    all_predict = []\n",
    "    all_y = []\n",
    "    for row in test:\n",
    "        predictions = [predict(tree, row) for tree in trees]\n",
    "        cur_predict = max(set(predictions), key=predictions.count)\n",
    "        all_y.append(row[-1])\n",
    "        all_predict.append(cur_predict)\n",
    "    return all_predict, r2_score(all_y, all_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-56f47bf6c4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4dcae65d9e72>\u001b[0m in \u001b[0;36mrandom_forest\u001b[0;34m(train, test, max_depth, min_size, sample_size, n_trees, n_features)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mall_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bd1f8ce335a6>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(train, max_depth, min_size, n_features)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbuild\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bd1f8ce335a6>\u001b[0m in \u001b[0;36mget_split\u001b[0;34m(dataset, n_features)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mgini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgini_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgini\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0ms_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0ms_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bd1f8ce335a6>\u001b[0m in \u001b[0;36mgini_index\u001b[0;34m(groups, class_values)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mproportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mgini\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproportion\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    (train, test) = k_fold_data[i]\n",
    "    _, score = random_forest(train, test, 10, 1, 0.8, 2, train[0].shape[0] - 1)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from multiprocessing import Lock, Queue, Pool\n",
    "lock = Lock()\n",
    "result = Queue()\n",
    "def append_tree(sample, max_depth, min_size, n_features):\n",
    "    tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "    result.put(tree)   \n",
    "p = Pool()\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "\n",
    "def multi_process_random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    trees = []\n",
    "    for i in range(n_trees):\n",
    "        sample = sub_sample(train, sample_size)\n",
    "        p.apply_async(build_tree, args=(sample, max_depth, min_size, n_features,))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    trees = []\n",
    "    while not result.empty():\n",
    "        trees.append(result.get())\n",
    "    all_predict = []\n",
    "    all_y = []\n",
    "    for row in test:\n",
    "        predictions = [predict(tree, row) for tree in trees]\n",
    "        cur_predict = max(set(predictions), key=predictions.count)\n",
    "        all_y.append(row[-1])\n",
    "        all_predict.append(cur_predict)\n",
    "    return all_predict, r2_score(all_y, all_predict)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "“pytorch”",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
