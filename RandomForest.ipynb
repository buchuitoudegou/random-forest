{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all data from train\n",
    "train_data = []\n",
    "train_label = []\n",
    "for i in range(5):\n",
    "    tmp = pd.read_csv('data/train%d' % i).values()\n",
    "    label = pd.read_csv('data/label%d' % i).values()\n",
    "    train_data.append(tmp)\n",
    "    train_label.append(label)\n",
    "x = train_data[0]\n",
    "y = train_label[0]\n",
    "for i in range(4):\n",
    "    x = np.vstack(x, train_data[i])\n",
    "    y = np.vstack(y, train_label[i])\n",
    "dataset = np.hstack(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    \"\"\"\n",
    "    description: split the current dataset by the `index`th feature and value\n",
    "    \"\"\"\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def gini_index(gourps, class_values):\n",
    "    \"\"\"\n",
    "    description: evaluate the gini value of the current groups, \n",
    "    containing the left group and the right group, splited by the nth feature.\n",
    "    `class_values` are all the possible values in the label column.\n",
    "    \"\"\"\n",
    "    gini = 0.0\n",
    "    for class_value in calss_values:\n",
    "        for gourp in groups:\n",
    "            if len(group) == 0:\n",
    "                continue\n",
    "            proportion = [row[-1] for row in group].count(class_value) / len(group)\n",
    "            gini += (proportion * (1.0 - proportion))\n",
    "    return gini\n",
    "\n",
    "def to_terminal(group):\n",
    "    \"\"\"\n",
    "    description: terminate the split and set the most frequent value as the output\n",
    "    \"\"\"\n",
    "    output = [row[-1] for row in group]\n",
    "    return max(set(output), key=output.count)\n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "    \"\"\"\n",
    "    description: choose a feature, which gains the highest gini value,\n",
    "    to split the dataset.\n",
    "    \"\"\"\n",
    "    class_values = [row[-1] for row in dataset]\n",
    "    s_index, s_value, s_score, s_groups = 999999, 999999, 999999, None\n",
    "    cur_features = [] # choose partition feature randomly\n",
    "    while len(cur_features) < log(2, n_features):\n",
    "        index = randrange(len(dataset[0] - 1))\n",
    "        if index not in features:\n",
    "            features.append(index)\n",
    "    for index in features:\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < s_score:\n",
    "                s_index, s_value, s_score, b_groups = index, row[index], gini, groups\n",
    "    return { 'index': s_index, 'value': s_value, 'groups': s_groups }\n",
    "\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    \"\"\"\n",
    "    description: split the node recursively.\n",
    "    \"\"\"\n",
    "    left, right = node['group']\n",
    "    del(node['group'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    \"\"\"\n",
    "    description: build a tree\n",
    "    \"\"\"\n",
    "    root = get_split(train, n_features)\n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    return root\n",
    "\n",
    "def predict(node, row):\n",
    "    \"\"\"\n",
    "    description: make prediction with the tree, navigating it and get the output\n",
    "    \"\"\"\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "\n",
    "def sub_sample(dataset, ratio):\n",
    "    \"\"\"\n",
    "    description: select the data ramdomly.\n",
    "    \"\"\"\n",
    "    sample = []\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_forest(train, test, max_depth, min_size, sample_size, n_tress, n_features):\n",
    "    trees = []\n",
    "    for i in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features)\n",
    "        tress.append(tree)\n",
    "    all_predict\n",
    "    for row in test:\n",
    "        predictions = [predict(tree, row) for tree in trees]\n",
    "        all_predict.append(max(set(predictions), key=predictions.count))\n",
    "    return all_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
